<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Word2vec ilustrado</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/custom.css" />
    <!-- <link rel="stylesheet" type="text/css" href="/assets/built/prism.css" /> -->
    <!-- highlight.js -->
    <!-- <link rel="stylesheet" href="/assets/built/styles/default.css"> -->
    <style>.hljs { background: none; }</style>
    <!-- night owl style  -->
    <link rel="stylesheet" href="/assets/built/styles/night-owl.css" />
    <style type='text/css'>
        pre, code {
            white-space: pre-wrap;
            overflow-x: scroll;
        }
        .hljs {
            display: inline-block;
            overflow-x: scroll;
            min-width: 100%;
        }
        .highlight {
            min-width: 100%;
        }
        div[class^="language-"] {
            min-width: 100%;
        }
    </style>

    

    
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    



    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Tu sitio para aprender de visualización y ciencia de datos en español. Consejos, recursos y mejores prácticas para tus proyectos de tecnología, periodismo de datos y análisis estadísticos." />
    <link rel="shortcut icon" href="https://old.tacosdedatos.com/assets/icons/favicon.ico" type="image/png" />
    <link rel="canonical" href="https://old.tacosdedatos.com/word-to-vec-ilustrado" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="🌮 tacos de datos | Aprende visualización de datos en español." />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Word2vec ilustrado" />
    <meta property="og:description" content="En esta ocasión les quiero hablar de otra forma de convertir texto a vectores, esta es distinta a las que hemos visto previamente ya que nos da como resultado un vector por cada token y cada uno de estos vectores es un vector denso. Esta vez les traigo no un" />
    <meta property="og:url" content="https://old.tacosdedatos.com/word-to-vec-ilustrado" />
    <meta property="og:image" content="https://old.tacosdedatos.com/assets/detrasdelavis/005.png" />
    <meta property="article:publisher" content="https://www.facebook.com/tacosdedatos" />
    <meta property="article:author" content="https://www.facebook.com/tacosdedatos" />
    <meta property="article:published_time" content="2020-09-04T10:00:00+00:00" />
    <meta property="article:modified_time" content="2020-09-04T10:00:00+00:00" />
    <meta property="article:tag" content="Python" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Word2vec ilustrado" />
    <meta name="twitter:description" content="En esta ocasión les quiero hablar de otra forma de convertir texto a vectores, esta es distinta a las que hemos visto previamente ya que nos da como resultado un vector por cada token y cada uno de estos vectores es un vector denso. Esta vez les traigo no un" />
    <meta name="twitter:url" content="https://old.tacosdedatos.com/" />
    <meta name="twitter:image" content="https://old.tacosdedatos.com/assets/detrasdelavis/005.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="🌮 tacos de datos | Aprende visualización de datos en español." />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Python" />
    <meta name="twitter:site" content="@tacosdedatos" />
    <meta name="twitter:creator" content="@tacosdedatos" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "🌮 tacos de datos | Aprende visualización de datos en español.",
        "logo": "https://old.tacosdedatos.com/assets/images/alt-blog-icon.png"
    },
    "url": "https://old.tacosdedatos.com/word-to-vec-ilustrado",
    "image": {
        "@type": "ImageObject",
        "url": "https://old.tacosdedatos.com/assets/detrasdelavis/005.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://old.tacosdedatos.com/word-to-vec-ilustrado"
    },
    "description": "En esta ocasión les quiero hablar de otra forma de convertir texto a vectores, esta es distinta a las que hemos visto previamente ya que nos da como resultado un vector por cada token y cada uno de estos vectores es un vector denso. Esta vez les traigo no un"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Word2vec ilustrado" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://old.tacosdedatos.com/"><img src="/assets/images/alt-blog-icon.png" alt="🌮 tacos de datos | Aprende visualización de datos en español." /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">inicio</a></li>
    <li class="nav-home" role="menuitem"><a href="https://medium.com/tacosdedatos/">la publiqueishon (Medium)</a></li>
    <li class="nav-about" role="menuitem"><a href="/sobre/">sobre 🌮</a></li>
    <li class="nav-podcast" role="menuitem"><a href="https://tacosdedatos.fm">podcast 🌮🎧</a></li>
    <li class="nav-recursos" role="menuitem"><a href="http://boletin.tacosdedatos.com/">el boletín</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/tacosdedatos" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/tacosdedatos" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Subscríbete</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full post tag-tutoriales ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime=" 4 September 2020"> 4 September 2020</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/python/'>PYTHON</a>,
                            
                        
                            
                               <a href='/tag/skelarn/'>SKELARN</a>,
                            
                        
                            
                               <a href='/tag/texto/'>TEXTO</a>,
                            
                        
                            
                               <a href='/tag/word2vec/'>WORD2VEC</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Word2vec ilustrado</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/detrasdelavis/005.png)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>En esta ocasión les quiero hablar de otra forma de convertir texto a vectores, esta es distinta a las que hemos visto previamente ya que nos da como resultado un vector por cada token y cada uno de estos vectores es un vector denso.</p>

<p>Esta vez les traigo no un post original, sino más bien una traducción de un artículo que me parece vale mucho la pena. El artículo original es de Jay Alammar y se llama <a href="http://jalammar.github.io/illustrated-word2vec/">The Illustrated Word2vec</a>:</p>

<hr />

<blockquote>
  <p>“Hay en todas las cosas un ritmo que es parte de nuestro universo. Hay simetría, elegancia y gracia… esas cualidades a las que se acoge el verdadero artista. Uno puede encontrar este ritmo en la sucesión de las estaciones, en la forma en que la arena modela una cresta, en las ramas de un arbusto creosota o en el diseño de sus hojas. 
Intentamos copiar este ritmo en nuestras vidas y en nuestra sociedad, buscando la medida y la cadencia que reconfortan. Y sin embargo, es posible ver un peligro en el descubrimiento de la perfección última. Está claro que el último esquema contiene en sí mismo su propia fijeza. En esta perfección, todo conduce hacia la muerte” ~ Frank Herbert. “Dune” (1965)</p>
</blockquote>

<p>Encuentro la idea de <em>embeddings</em>* una de las más fascinantes dentro del aprendizaje automático. Si alguna vez has usado <em>Siri</em>, <em>Google Assistant</em>, <em>Alexa</em> o <em>Google Translate</em>, o inclusive un teléfono con teclado que predice tu siguiente palabra, entonces seguramente te has beneficiado de esta idea que se a convertido en la clave de los modelos de Procesamiento de Lenguaje Natural (<em>NLP</em>). En las últimas décadas ha existido mucho desarrollo respecto a usar <em>embeddings</em> para modelos neuronales (investigaciones recientes incluyen <em>embeddings</em> contextualizados que llevan a modelos vanguardistas como <a href="https://jalammar.github.io/illustrated-bert/">BERT</a> o GPT2).</p>

<p><strong>Word2vec</strong> es un método para crear <em>embeddings</em> de forma eficiente que ha existido desde 2013. pero además de su utilidad para la creación de estos <em>embeddings</em>, algunos de sus conceptos han sido exitosamente empleados para crear modelos de recomendación y para hacer sentido de datos secuenciales, inclusive en aplicaciones comerciales no relacionadas con lenguajes. Compañías como <a href="https://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb">Airbnb</a>, <a href="https://www.kdd.org/kdd2018/accepted-papers/view/billion-scale-commodity-embedding-for-e-commerce-recommendation-in-alibaba">Alibaba</a>, <a href="https://www.slideshare.net/AndySloane/machine-learning-spotify-madison-big-data-meetup">Spotify</a>, y <a href="https://towardsdatascience.com/using-word2vec-for-music-recommendations-bb9649ac2484">Anghami</a> le han sacado provecho a esta brillante pieza del mundo del <em>NLP</em> y la están usando para potenciar una nueva clase de modelos de recomendación.</p>

<p>En este post, vamos a revisar el concepto de <em>embeddings</em>, y cómo es que se generan estos con la técnica de <em>word2vec</em>. Pero comencemos con un ejemplo para familiarizarnos con el uso de vectores para representar cosas. ¿Sabías que una lista de cinco números (es decir, un vector) puede representar mucho sobre tu personalidad?</p>

<h2 id="embeddings-de-personalidad-cómo-eres"><em>Embeddings</em> de personalidad: ¿cómo eres?</h2>

<blockquote>
  <p>“Te doy el camaleón del desierto, cuya habilidad para mezclarse con el fondo te dice todo lo que necesitas saber sobre las raíces de la ecología y las bases de la identidad personal” ~ Hijos de Dune</p>
</blockquote>

<p>En una escala de 0 a 100, ¿qué tan introvertido/extrovertido eres tu (donde 0 es introvertido, y 100 es extrovertido)? ¿alguna vez has tomado un test de personalidad como MBTI – o, mejor aún, una prueba del <a href="https://es.wikipedia.org/wiki/Modelo_de_los_cinco_grandes">modelo de los cinco grandes</a>? si no lo has hecho, este tipo de pruebas te hace una serie de preguntas y te califica en diferentes ejes, siendo la introversión o extraversión uno de ellos.</p>

<p><img src="http://jalammar.github.io/images/word2vec/big-five-personality-traits-score.png" alt="" /></p>

<p><small>Ejemplo de un resultado en una prueba del modelo de los cinco grandes. Este te puede decir mucho sobre ti mismo y ha mostrado tener habilidades predictivas en cuanto a éxito <a href="http://psychology.okstate.edu/faculty/jgrice/psyc4333/FiveFactor_GPAPaper.pdf">académico</a>, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1744-6570.1999.tb00174.x">personal</a> y <a href="https://www.massgeneral.org/psychiatry/assets/published_papers/soldz-1999.pdf">profesional</a>. <a href="https://projects.fivethirtyeight.com/personality-quiz/">Aquí</a> puedes calcular tus valores.</small></p>

<p>Imagina que obtuve 38/100 en el eje de introversión/extroversión. Lo podemos graficar así:</p>

<p><img src="http://jalammar.github.io/images/word2vec/introversion-extraversion-100.png" alt="" /></p>

<p>Si colocamos los valores de -1 a 1:</p>

<p><img src="http://jalammar.github.io/images/word2vec/introversion-extraversion-1.png" alt="" /></p>

<p>¿Qué tan bien crees conocer a una persona si sabes solo esta información sobre ella? No mucho, las personas son complejas. Añadamos otra dimensión, la calificación de otra de las características del test:</p>

<p><img src="http://jalammar.github.io/images/word2vec/two-traits-vector.png" alt="" /></p>

<p><small>Podemos representar dos dimensiones como un punto en la gráfica, o mejor aún, como un vector desde el origen a ese punto. Tenemos herramientas increíbles que para trabajar con vectores que nos resultarán útiles más adelante.</small></p>

<p>He ocultado qué características estamos graficando solamente para que nos acostumbremos a no saber qué representa cada dimensión – aun asi, estamos obteniendo mucha información de la representación vectorial de cada una de las personalidades.</p>

<p>Ahora podemos decir que este vector representa parcialmente mi personalidad. La usabilidad de esta representación es útil cuando quieres comparar otras dos personas conmigo. Digamos que me atropella un autobús y debo ser reemplazado por alguien con una personalidad similar. Dada la siguiente figura, ¿cuál de las dos personas es más similar a mi?</p>

<p><img src="http://jalammar.github.io/images/word2vec/personality-two-persons.png" alt="" /></p>

<p>Cuando estamos trabajando con vectores, una forma común de calcular una medida de similitud es la <a href="https://es.wikipedia.org/wiki/Similitud_coseno">similitud coseno</a> (o <em>cosine similarity</em> que es su nombre en inglés).</p>

<p><img src="http://jalammar.github.io/images/word2vec/cosine-similarity.png" alt="" /></p>

<p><small><span style="color: #70BF41;">Person #1</span> es más similar a mi en cuanto a personalidad. Vectores que apuntan a la misma dirección (aunque la longitud también tiene que ver) tienen una similitud coseno más grande.</small></p>

<p>Aun asi, dos dimensiones no son suficientes para capturar información suficiente sobre qué tan diferentes dos personas son. Décadas de investigación psicológica han llevado a que existen 5 características (y muchas sub-características). Así que vamos a usar todas en nuestras comparaciones:</p>

<p><img src="http://jalammar.github.io/images/word2vec/big-five-vectors.png" alt="" /></p>

<p>El problema con estas cinco dimensiones es que hemos perdido la habilidad de graficar esas flechitas tan bonitas en dos dimensiones. Este es un obstáculo común en el aprendizaje automático en el que constantemente tenemos que pensar en espacios de grandes dimensiones. La ventaja que teneos es que la similitud coseno aún funciona sin importar las dimensiones:</p>

<p><img src="http://jalammar.github.io/images/word2vec/embeddings-cosine-personality.png" alt="" /></p>

<p><small>La similitud coseno funciona sin importar el número de dimensiones. Estas son mejores calificaciones porque han sido calculadas en una representación con mayor resolución de las cosas que están siendo comparadas.</small></p>

<p>Para concluir esta sección, quiero que nos quedemos con dos ideas principales:</p>

<ol>
  <li>Podemos representar personas (y cosas) como vectores de números (lo que es perfecto para las computadoras).</li>
  <li>Podemos comparar fácilmente qué tan similares son los vectores entre sí.</li>
</ol>

<p><img src="http://jalammar.github.io/images/word2vec/section-1-takeaway-vectors-cosine.png" alt="" /></p>

<h2 id="embeddings-de-palabras"><em>Embeddings</em> de palabras</h2>

<blockquote>
  <p>“El don de las palabras es el don del engaño y la ilusión” ~ Hijos de Dune</p>
</blockquote>

<p>Entendiendo esto, podemos proceder a ver ejemplos de vectores-palabra entrenados (también conocidos como <em>embeddings</em>) y ver algunas de sus propiedades interesantes.</p>

<p>Este es un <em>embedding</em> para la palabra <em>“king”</em> –rey, en inglés– (GloVe vector entrenado en Wikipedia):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ 0.50451 , 0.68607 , -0.59517 , -0.022801, 0.60046 , -0.13498 , -0.08813 , 0.47377 , -0.61798 , -0.31012 , -0.076666, 1.493 , -0.034189, -0.98173 , 0.68229 , 0.81722 , -0.51874 , -0.31503 , -0.55809 , 0.66421 , 0.1961 , -0.13495 , -0.11476 , -0.30344 , 0.41177 , -2.223 , -1.0756 , -1.0783 , -0.34354 , 0.33505 , 1.9927 , -0.04234 , -0.64319 , 0.71125 , 0.49159 , 0.16754 , 0.34344 , -0.25663 , -0.8523 , 0.1661 , 0.40102 , 1.1685 , -1.0137 , -0.21585 , -0.15155 , 0.78321 , -0.91241 , -1.6106 , -0.64426 , -0.51042 ]
</code></pre></div></div>

<p>Es una lista de 50 números. No podemos decir mucho si solamente vemos estos números.</p>

<p><img src="http://jalammar.github.io/images/word2vec/king-white-embedding.png" alt="" /></p>

<p>Añadamos colores a las celdas basados en sus valores (rojo si están cerca de 2, blanco si están cerca de 0 y azul si están cerca de -2):</p>

<p><img src="http://jalammar.github.io/images/word2vec/king-colored-embedding.png" alt="" /></p>

<p>De ahora en adelante, vamos a ignorar los números y concentrarnos solo en los colores que indican los valores de las celdas. Comparemos <em>“king”</em> contra otras palabras:</p>

<p><img src="http://jalammar.github.io/images/word2vec/king-man-woman-embedding.png" alt="" /></p>

<p>¿Ves cómo las palabras <em>“man”</em> y <em>“woman”</em> son más similares entre sí que cualquiera de ellas con <em>“king”</em>? Esto nos dice algo. Estas representaciones vectoriales capturan un poco la información/significado/asociaciones de estas palabras.</p>

<p>Aquí hay otros ejemplos (compara las columnas verticalmente, buscando columas con colores similares):</p>

<p><img src="https://jalammar.github.io/images/word2vec/queen-woman-girl-embeddings.png" alt="" /></p>

<p>Algunas cosas para destacar:</p>

<ol>
  <li>Hay una columna roja que coincide en todas las palabras. Las palabras son similares en esa dimensión (recuerda que no sabemos lo que significa cada dimensión).</li>
  <li>Puedes ver cómo <em>“woman”</em> y <em>“girl”</em> son similares en un montón de lugares. Lo mismo sucede con <em>“man”</em> y <em>“boy”</em>.</li>
  <li><em>“boy”</em> y <em>“girl”</em> también tienen lugares en donde coinciden, pero son lugares diferentes a <em>“woman”</em> o <em>“man”</em>. ¿Será que estas estén codificando una vaga definición de juventud? es posible.</li>
  <li>Todas las palabras, excepto la última representan personas. Agregué, por ejemplo, un objeto (<em>“water”</em>) para mostrar las diferencias entre categorías. Por ejemplo, ¿ves esa columna azul fuerte a la derecha que se atenúa cuando llegamos al <em>embedding</em> de <em>“water”</em>?</li>
  <li>Hay otros lugares en donde <em>“king”</em> y <em>“queen”</em> son diferentes de todas las demás, ¿será que estas diferencias codifiquen un concepto vago de realeza?</li>
</ol>

<h3 id="analogías">Analogías</h3>

<blockquote>
  <p>“Las palabras pueden llevar todo el peso que queramos. Todo lo que se requiere es un acuerdo tradición a partir de la cual  construir” ~ Dios emperador de Dune</p>
</blockquote>

<p>Los ejemplos más usados que muestran una de las características más increíbles de los <em>embeddings</em> es el concepto de analogías. Podemos sumar y restar <em>embeddings</em> y llegar a resultados interesantes. El ejemplo más famoso es la fórmula <em>“king”</em> - <em>“man”</em> + <em>“woman”</em>:</p>

<p><img src="https://jalammar.github.io/images/word2vec/king-man+woman-gensim.png" alt="" /></p>

<p><small>Usando la biblioteca <a href="https://radimrehurek.com/gensim/">Gensim</a> de Python, podemos sumar y restar vectores, y encontrar las palabras más similares al vector resultante. La imagen muestra una lista de las palabras más similares, cada una con su similitud coseno.</small></p>

<p>Podemos visualizar esta analogía como lo hemos hecho anteriormente:</p>

<p><img src="https://jalammar.github.io/images/word2vec/king-analogy-viz.png" alt="" /></p>

<p><small>El vector resultante de <em>“king-man+woman”</em> no coincide exactamente con <em>“queen”</em> es la más cercana de las 400,000 que la contiene este <em>dataset</em>.</small></p>

<p>Ahora que hemos revisado los <em>embeddings</em>, aprendamos más acerca del proceso para obtenerlos. Pero antes de que lleguemos a <em>word2vec</em>, necesitamos conocer a su padre conceptual: los modelos de lenguaje neuronales.</p>

<h2 id="modelando-lenguajes">Modelando lenguajes</h2>

<blockquote>
  <p>“El profeta no se distrae con ilusiones del pasado, presente y futuro. <strong>La fijeza del lenguaje determina tales distinciones lineales.</strong> Los profetas sostienen la llave de la cerradura en un idioma. 
Este no es un universo mecánico. La progresión lineal de los eventos la impone el observador. ¿Causa y efecto? No es eso para nada. <strong>El profeta pronuncia palabras fatídicas.</strong> Vislumbras algo “destinado a ocurrir” pero el instante profético libera algo de portento y poder infinitos. El universo sufre un cambio fantasmal” ~ Dios emperador de Dune</p>
</blockquote>

<p>Si uno quisiera un ejemplo de una aplicación que usa <em>NLP</em>, uno de los mejores sería la predicción de la próxima palabra en el teclado de un teléfono. Es una característica que miles de millones de personas usan cientos de veces al día.</p>

<p><img src="http://jalammar.github.io/images/word2vec/swiftkey-keyboard.png" alt="" /></p>

<p>La predicción de la próxima palabra es una tarea que puede llevarse a cabo usando un <em>modelo de lenguage</em> (<em>language model</em>, en inglés). Un modelo de lenguaje puede tomar una lista de palabras (digamos, dos), y tratar de predecir cuál es la que le seguiría.</p>

<p>En la captura de pantalla de arriba, podemos pensar que el modelo tomó estas dos palabras en color verde (<span style="color: #70BF41;">Thou</span>, <span style="color: #70BF41;">shalt</span>) y regresa un conjunto de sugerencias (“not” es la que tenía la mayor probabilidad):</p>

<p><img src="http://jalammar.github.io/images/word2vec/thou-shalt-_.png" alt="" /></p>

<p>Puedes pensar en el modelo como una caja negra:</p>

<p><img src="http://jalammar.github.io/images/word2vec/language_model_blackbox.png" alt="" /></p>

<p>Pero en la práctica, el modelo no solamente regresa como resultado una sola palabra. En realidad, entrega las probabilidades para todas las palabras que “conoce” (el conjunto de todas las palabras que conoce se llama vocabulario, que pueden ir desde unas cuantas miles hasta millones de palabras). Es la responsabilidad del teclado encontrar las palabras con mayor probabilidad y presentarlas al usuario.</p>

<p><img src="http://jalammar.github.io/images/word2vec/language_model_blackbox_output_vector.png" alt="" /></p>

<p><small>Los resultados de un modelo de lenguaje son probabilidades sobre todas las palabras que el modelo “conoce”. En la imagen nos referimos a la probabilidad como porcentaje, pero ese 40% en realidad vale 0.4 en nuestro vector de salida.</small></p>

<p>Después de ser entrenado, los primeros modelos de lenguaje (<a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">Bengio 2003</a>) calculaban la predicción en tres pasos:</p>

<p><img src="http://jalammar.github.io/images/word2vec/neural-language-model-prediction.png" alt="" /></p>

<p>El primer paso es el más relevante para nosotros porque en este post estamos hablando sobre los <em>embeddings</em>. Uno de los resultados del proceso de entrenamiento es una matriz que contiene un <em>embedding</em> por cada uno de los tokens en nuestro vocabulario. Cuando estamos prediciendo, simplemente buscamos los <em>embeddings</em> de los tokens de entrad ay calculamos la predicción:</p>

<p><img src="http://jalammar.github.io/images/word2vec/neural-language-model-embedding.png" alt="" /></p>

<p>Ahora vamos a aprender cómo es que esta matriz de <em>embeddings</em> es creada.</p>

<h2 id="entrenamiento-de-modelos-de-lenguaje">Entrenamiento de modelos de lenguaje</h2>

<blockquote>
  <p>“Un proceso no se puede entender deteniéndolo. La comprensión debe moverse con el flujo del proceso, debe unirse y fluir con él.” ~Dune</p>
</blockquote>

<p>Los modelos de lenguaje tienen una gran ventaja sobre otros modelos de <em>machine learning</em>. Esa ventaja es que podemos entrenarlos usando texto – del cual tenemos mucho. Piensa en todos los libros, artículos, y otras formas de textos a nuestro al rededor. En contraste con otros modelos de aprendizaje automático que necesitan que la los datos sean preparados (y a veces obtenidos) específicamente para ellos.</p>

<blockquote>
  <p>“Conocerás una palabra por sus la compañía que mantiene alrededor” ~ J.R. Firth</p>
</blockquote>

<p>Las palabras obtienen sus <em>embeddings</em> a partir de las palabras que aparecen a su alrededor. Esto funciona de la siguiente manera:</p>

<ol>
  <li>Obtenemos un montón de texto (digamos, todos los artículos de Wikipedia), luego</li>
  <li>tomamos una ventana (digamos, de tres palabras) que movemos sobre todo el texto,</li>
  <li>Esta ventana genera nuestros ejemplos para el entrenamiento del modelo:</li>
</ol>

<p><img src="http://jalammar.github.io/images/word2vec/wikipedia-sliding-window.png" alt="" /></p>

<p>En tanto esta ventana se desliza, nosotros (virtualmente) generamos un <em>dataset</em> que usaremos para entrenar el modelo. Para ver cómo es que esto funciona, veamos cómo funciona el proceso para la siguiente frase:</p>

<blockquote>
  <p>“Thou shalt not make a machine in the likeness of a human mind” ~Dune</p>
</blockquote>

<p>Cuando empezamos, la ventana está en las tres primeras palabras de la oración:</p>

<p><img src="http://jalammar.github.io/images/word2vec/lm-sliding-window.png" alt="" /></p>

<p>Tomamos las dos palabras como <em>features</em>, y la tercera como la etiqueta a predecir:</p>

<p><img src="http://jalammar.github.io/images/word2vec/lm-sliding-window-2.png" alt="" /></p>

<p>Luego entonces deslizamos la ventana a la siguiente posición para generar un segundo ejemplo de entrenamiento:</p>

<p><img src="http://jalammar.github.io/images/word2vec/lm-sliding-window-3.png" alt="" /></p>

<p>Y de pronto tendremos un gran <em>dataset</em> de palabras que suelen aparecer después de otro par:</p>

<p><img src="http://jalammar.github.io/images/word2vec/lm-sliding-window-4.png" alt="" /></p>

<p>En la práctica, los modelos suelen ser entrenados mientras esta ventana se va deslizando, sin embargo, siento que es más claro separar lógicamente la etapa de generación del <em>dataset</em> de la etapa de entrenamiento. Además de modelos basados en redes neuronales, existe una técnica conocida como <em>n-grams</em> que es también usada comúnmente para entrenar modelos (mira el capítulo 3 de <a href="http://web.stanford.edu/~jurafsky/slp3/"><em>Speech and Language Processing</em></a>). para ver cómo es que este cambio de <em>n-grams</em> a modelos neuronales se refleja en productos reales, revisa <a href="https://blog.swiftkey.com/neural-networks-a-meaningful-leap-for-mobile-typing/">este post de Swiftkey</a> mi teclado favorito para Android, introduciendo su modelo neuronal de lenguaje y comparándolo con su previo modelo basado en <em>n-grams</em>. me gusta este ejemplo porque muestra cómo las propiedades algorítmicas de los <em>embeddings</em> se pueden describir en lenguaje de marketing.</p>

<h3 id="mira-hacia-ambos-lados">Mira hacia ambos lados</h3>

<blockquote>
  <p>“La paradoja es un indicador que te dice que mires más allá. Si las paradojas te molestan, eso delata tu profundo deseo de absolutos. El relativista trata una paradoja simplemente como interesante, quizás divertida o incluso, un pensamiento terrible, educativo” ~ Dios emperador de Dune</p>
</blockquote>

<p>Sabiendo de lo que hablamos anteriormente en este post, completa la oración</p>

<p><img src="http://jalammar.github.io/images/word2vec/jay_was_hit_by_a_.png" alt="" /></p>

<p>El contexto que te he dado aquí son 5 palabras antes del espacio en blanco. Estoy seguro que la mayoría de las personas elegirían la palabra <em>“bus”</em> como solución. Pero qué sucedería si te doy un poco más de información – una palabra después del espacio en blanco, ¿cambiaría tu respuesta?</p>

<p><img src="http://jalammar.github.io/images/word2vec/jay_was_hit_by_a_.png" alt="" /></p>

<p>Esto cambia completamente lo que debería ir en el espacio en blanco, la palabra <em>“red”</em> es ahora la que tiene mayor sentido de ser elegida. Lo que hemos aprendido de esto es que tanto las palabras previas como las siguientes a una palabra determinada contienen un alto valor sobre esta palabra determinada. Resulta que tomar en cuenta ambas direcciones (palabras a la izquierda y derecha de la que estamos adivinando) nos lleva a tener mejor <em>embeddings</em>. Veamos cómo es que podemos tomar en cuenta esto al momento de entrenar nuestro modelo.</p>

<h2 id="skipgram"><em>Skipgram</em></h2>

<blockquote>
  <p>“La inteligencia se arriesga con datos limitados en un campo donde los errores no solo son posibles sino también necesarios.” ~Chapterhouse: Dune</p>
</blockquote>

<p>En lugar de solamente mirar dos palabras antes de nuestra palabra objetivo, podemos también ver dos palabras después:</p>

<p><img src="http://jalammar.github.io/images/word2vec/continuous-bag-of-words-example.png" alt="" /></p>

<p>Si hacemos esto, el <em>dataset</em> que estamos construyendo virtualmente para entrenar el modelo se vería así:</p>

<p><img src="http://jalammar.github.io/images/word2vec/continuous-bag-of-words-dataset.png" alt="" /></p>

<p>Esta arquitectura es conocida como <em>Continuous Bag of Words</em> y es descrita en uno de los <a href="https://arxiv.org/pdf/1301.3781.pdf">artículos de word2vec</a>. Hay otra arquitectura que entregó grandes resultados haciendo las cosas un poco diferente.</p>

<p>El lugar de “adivinar” una palabra a partir de su contexto (las palabras antes y después de ella), esta otra arquitectura trata de predecir las palabras vecinas a partir de una palabra determinada. Podemos imaginar que la ventana se desliza sobre el texto de entrenamiento así:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window.png" alt="" /></p>

<p><small>La palabra en la casilla verde será tratada como la palabra de entrada y cada una de las casillas rosas serán tratadas como posibles resultados.</small></p>

<p>Las casillas rosas están marcadas con diferentes tonalidades porque la ventana deslizante en realidad crea cuatro ejemplos diferentes en nuestro dataset:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-samples.png" alt="" /></p>

<p>Este método es conocido como la arquitectura <em>skipgram</em>. Podemos visualizar la ventana deslizante haciendo algo así:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-1.png" alt="" /></p>

<p>Esto añadiría cuatro ejemplos a nuestro dataset de entrenamiento:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-2.png" alt="" /></p>

<p>Luego entonces podemos deslizar la ventana a su siguiente posición:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-3.png" alt="" /></p>

<p>Esto genera otros cuatro ejemplos:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-4.png" alt="" /></p>

<p>Un par de posiciones más adelante tenemos muchos más ejemplos:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-sliding-window-5.png" alt="" /></p>

<h2 id="revisando-el-proceso-de-entrenamiento">Revisando el proceso de entrenamiento</h2>

<blockquote>
  <p>“Muad’Dib aprendió rápidamente porque su primer entrenamiento fue sobre cómo aprender. Y la primera lección de todas fue la confianza básica que podía aprender. Es impactante descubrir cuántas personas no creen que puedan aprender y cuántas más creen que aprender es difícil.” ~ Dune</p>
</blockquote>

<p>Ahora que ya tenemos nuestro <em>dataset</em> creado a partir del modelo <em>skipgram</em>, echemos un vistazo a cómo lo podemos usar para entrenar un modelo neuronal básico de lenguaje que predice las palabras vecinas a otra.</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-language-model-training.png" alt="" /></p>

<p>Comencemos por el primer ejemplo en nuestro <em>dataset</em>. Tomando la primer entrada y dándosela al modelo que aún no está entrenado pidiéndole su predicción para la siguiente palabra.</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-language-model-training-2.png" alt="" /></p>

<p>El modelo ejecuta los tres pasos definidos arriba y entrega un vector de predicción (en donde cada palabra en su vocabulario recibe una probabilidad). Dado que el modelo no está entrenado aún, sus predicciones son incorrectas en esta etapa; eso está bien. Nosotros sabemos qué palabra debió haber predicho – la palabra (o “etiqueta”) en la fila que estamos usando para entrenar el modelo:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-language-model-training-3.png" alt="" /></p>

<p><small>El vector objetivo (<em>“target vector”</em>) es aquel en donde la verdadera palabra esperada tiene una probabilidad de 1 mientras que cualquier otra tienen probabilidad 0.</small></p>

<p>¿Qué tan lejos estuvo el modelo? para saber esto, restamos los dos vectores (el valor esperado menos el valor predecido) lo cual nos va a dar un vector “error”:</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-language-model-training-4.png" alt="" /></p>

<p>Este vector “error” puede ser usado para actualizar el modelo para que, la siguiente vez que se le pregunte, sea más probable que “adivine” <span style="color: #e91e63;">thou</span> cuando recibe <span style="color: #4caf50;">not</span> como entrada.</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-language-model-training-5.png" alt="" /></p>

<p>Y así concluye el primer paso del entrenamiento. Procedemos a ejecutar el mismo proceso con el siguiente ejemplo en nuestro dataset, y el siguiente, y el siguiente y así hasta que hayamos terminado de cubrir todos los ejemplos de nuestro <em>dataset</em>, con eso se cubre lo que en <em>machine learning</em> se conoce como una <strong>época de entrenamiento</strong>. Después repetimos el mismo proceso por un número de épocas y finalmente podemos extraer la matriz de <em>embeddings</em> (que son los parámetros internos de nuestro modelo neuronal) y usarla para cualquier otra aplicación.</p>

<p>Mientras qué hemos logrado entender el proceso, aún no llegamos a cómo es que <em>word2vec</em> fue entrenado en realidad. Nos faltan un par de ideas claves.</p>

<h2 id="sampleo-negativo">Sampleo negativo</h2>

<blockquote>
  <p>“Intentar comprender a Muad’Dib sin comprender a sus enemigos mortales, los Harkonnen, es intentar ver la Verdad sin conocer la Falsedad. Es el intento de ver la Luz sin conocer la Oscuridad. No puede ser.” ~ Dune</p>
</blockquote>

<p>Recordemos los tres pasos de cómo es que este modelo neuronal calcula su predicción:</p>

<p><img src="http://jalammar.github.io/images/word2vec/language-model-expensive.png" alt="" /></p>

<p>Este tercer paso es muy costoso desde un punto de vista computacional – especialmente sabiendo que tenemos que hacerlo una vez por cada ejemplo en nuestro dataset (que fácilmente será millones de veces). Necesitamos hacer algo para mejorar el desempeño.</p>

<p>Una forma de hacerlo es dividiendo nuestro objetivo en dos etapas:</p>

<ol>
  <li>Generar <em>embeddings</em> de alta calidad (sin preocuparnos por predecir la siguiente palabra)</li>
  <li>Usar estos <em>embeddings</em> para entrenar un modelo de lenguaje (para ahora si, predecir la siguiente palabra)</li>
</ol>

<p>Nos vamos a enfocar en el paso 1, ya que este post se trata de <em>embeddings</em>. Para generar unos de alta calidad mientras que usamos un modelo de alto desempeño podemos cambiar la funcionalidad del modelo de predecir la siguiente palabra:</p>

<p><img src="http://jalammar.github.io/images/word2vec/predict-neighboring-word.png" alt="" /></p>

<p>A uno que tome las dos palabras (la de entrada y la que sería de salida) y regrese una medida indicando si estas palabras son vecinas o no (0 para “no vecinas”, 1 para “vecinas”):</p>

<p><img src="http://jalammar.github.io/images/word2vec/are-the-words-neighbors.png" alt="" /></p>

<p>Este simple cambio también significa que podemos cambiar nuestro modelo de salidas de múltiples salidas a un modelo de regresión lineal – que se convierte en uno más sencillo y fácil de entrenar.</p>

<p>Este cambio también requiere que nosotros cambiemos la estructura de nuestro <em>dataset</em> – lo que era antes nuestra etiqueta ahora es otra entrada al modelo, y el valor a predecir es 0 o 1. Por ahora todos serán 1 puesto que todas nuestras palabras son “vecinas”.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-dataset.png" alt="" /></p>

<p>Este problema puede ser resuelto a una velocidad impresionante – procesando millones de ejemplos en minutos; sin embargo, existe un pequeño problema que debemos solucionar. Si todos nuestros ejemplos son positivos (es decir, etiqueta 1), nos estamos exponiendo a que nuestro modelo se pase de listillo y siempre regrese 1 como respuesta – logrando 100% de precisión pero sin aprender nada (y en el proceso generar <em>embeddings</em> que no sirven).</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-smartass-model.png" alt="" /></p>

<p>Para resolver esto, necesitamos incluir <em>ejemplos negativos</em> en nuestro <em>dataset</em> – ejemplos de palabras que no tienen relación y para las cuales nuestro modelo debe regresar 0 como predicción. Con eso tenemos ahora un verdadero reto para el cual nuestro modelo tiene que trabajar para resolver, sin embargo este proceso sigue siendo rápido.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-negative-sampling.png" alt="" /></p>

<p><small>Para cada ejemplo en nuestro <em>dataset</em>, añadimos un ejemplo negativo. Estos tienen la misma palabra de “entrada” y 0 como etiqueta.</small></p>

<p>Pero, ¿qué colocamos como palabras de “salida”? pues podemos elegir palabras de nuestro vocabulario aleatoriamente:</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-negative-sampling-2.png" alt="" /></p>

<p>Esta idea está inspirada por <a href="http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf"><em>noise-constrative estimation</em></a>. Nosotros estamos contrastando la verdadera señal (los ejemplos positivos de palabras vecinas) con ruido (los ejemplos de palabras que no son vecinas elegidos aleatoriamente). Esto representa un excelente balance entre eficiencia computacional y estadística.</p>

<h2 id="skipgram-con-sampleo-negativo"><em>Skipgram</em> con sampleo negativo</h2>

<p>Ahora hemos cubierto dos de las ideas centrales en <em>word2vec</em>: en conjunto son llamadas <em>skipgram</em> con sampleo negativo (*Skipgram with Negative Sampling, SGNS)</p>

<p><img src="http://jalammar.github.io/images/word2vec/skipgram-with-negative-sampling.png" alt="" /></p>

<h2 id="proceso-de-entrenamiento-de-word2vec">Proceso de entrenamiento de <em>Word2vec</em></h2>

<blockquote>
  <p>“La computadora no puede anticipar todos los problemas de importancia para los humanos. Es la diferencia entre bits en serie y un continuo ininterrumpido. Nosotros tenemos este; las máquinas se limitan al otro.” ~ Dune</p>
</blockquote>

<p>Antes de que el proceso de entrenamiento comience, tenemos que pre-procesar el texto que vamos a usar para entrenar el modelo. Por ejemplo, determinamos el tamaño de nuestro vocabulario (llamaremos a este valor <span style="color:#ffa000;">vocab_size</span>, y digamos que su valor es 10,000) y qué palabras pertenecen a este.</p>

<p>Al principio de la face de entrenamiento creamos dos matrices – una de <span style="color: #4caf50;">Embedding</span> y otra de <span style="color: #9c27b0;">Contexto</span>. Estas dos matrices tienen un vector (<em>embedding</em>) para cada palabra en el vocabulario, es decir <span style="color:#ffa000;">vocab_size</span> es el tamaño de una de sus dimensiones. La segunda dimensión es qué tan largo queremos que el <em>embedding</em> sea (llamemos a este parámetro <span style="color: #ff6f00;">embedding_size</span>), 300 es un valor común, aunque anteriormente vimos un ejemplo de 50.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-embedding-context-matrix.png" alt="" /></p>

<p>Cuando el proceso de entrenamiento comienza, rellenamos estas matrices con valores aleatorios. En cada paso de entrenamiento, tomamos un ejemplo positivo y su correspondiente negativo. Veámoslo con el primer grupo:</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-example.png" alt="" /></p>

<p>Ahora tenemos cuatro palabras: la de entrada <span style="color: #4caf50;">not</span> y la de salida o contexto <span style="color: #9c27b0;">thou</span> (que es su vecina). Además, tenemos <span style="color: #9c27b0;">aaron</span> y <span style="color: #9c27b0;">taco</span> como ejemplos negativos. Con esto en mente, ubicamos sus <em>embeddings</em>: para la palabra de entrada, buscamos en la matriz <span style="color: #4caf50;">Embedding</span> mientras que para las palabras “contexto” los buscamos en la matriz <span style="color: #9c27b0;">Contexto</span> (a pesar de que ambas matrices tienen un <em>embedding</em> para cada palabra en nuestro vocabulario).</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-lookup-embeddings.png" alt="" /></p>

<p>Después, tomamos el producto punto (<em>dot product</em>) del <em>embedding</em> de entrada con los <em>embeddings</em> contexto. En cada caso, este producto punto resultará en un número que indica la similtud entre estas dos palabras:</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-dot-product.png" alt="" /></p>

<p>Necesitamos una forma de convertir estos valores en algo que parezca probabilidades – necesitamos que todas sean positivas y con valores entre 0 y 1. Este es un buen lugar para usar <a href="https://jalammar.github.io/feedforward-neural-networks-visual-interactive/#sigmoid-visualization"><em>sigmoid</em></a>.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-dot-product-sigmoid.png" alt="" /></p>

<p>Ahora podemos tratar la salida de la operación <em>sigmoid</em> como la salida del modelo para estos ejemplos. Puedes ver que <span style="color: #9c27b0;">taco</span> tiene el valor mayor mientras que <span style="color: #9c27b0;">aaron</span> el menor, ambos antes y después de la operación <em>sigmoid</em>.</p>

<p>Una vez que el modelo no entrenado ha hecho una predicción, y sabiendo que tenemos un resultado correcto contra el cual comparar, vamos a calcular cuál fue el error en las predicciones del modelo. Para hacer eso, basta con restar los valores obtenidos de <em>sigmoid</em> contra el valor de salida verdadero (<em>target</em>):</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-error.png" alt="" /></p>

<p>Aquí es donde viene la parte del <em>learning</em> en <em>machine learning</em>. Una vez que calculamos el error, podemos usarlo para ajustar los embeddings de nuestrass palabras, para que la próxima vez que necesitemos una predicción, los valores predecidos sean más parecidos a los valores esperados.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-update.png" alt="" /></p>

<p>Con esto concluye un primer paso de entrenamiento. Una vez concluido, terminamos con <em>embeddings</em> un poquito mejores para las palabras involucradas en él (<span style="color: #4caf50;">not</span>, <span style="color: #9c27b0;">thou</span>, <span style="color: #9c27b0;">aaron</span> y <span style="color: #9c27b0;">taco</span>). Ahora si, podemos pasar al siguiente paso, es decir, el siguiente ejemplo positivo y sus correspondientes negativos para ejecutar el proceso nuevamente.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-training-example-2.png" alt="" /></p>

<p>Los <em>embeddings</em> seguirán mejorando mientras iteramos sobre todo nuestro <em>dataset</em>. En cualquier momento podemos detener el proceso de entrenamiento, descartar la matriz <span style="color: #9c27b0;">Contexto</span> y usar los <em>embeddings</em> en la matriz <span style="color: #4caf50;">Embedding</span> para cualquier otra tarea.</p>

<h2 id="tamaño-de-ventana-y-número-de-ejemplos-negativos">Tamaño de ventana y número de ejemplos negativos</h2>

<p>Hay dos híper parámetros claves en el proceso de entrenamiento de <em>word2vec</em>, estos son el tamaño de la ventana y el número de ejemplos negativos.</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-window-size.png" alt="" /></p>

<p>Diferentes tareas se benefician de diferentes tamaños de ventana. Una <a href="https://youtu.be/tAxrlAVw-Tk?t=648">heurística</a> que podemos emplear es que tamaños de ventana pequeños (2-15) llevan a <em>embeddings</em> donde altos valores de similitud indican que las palabras son intercambiables (toma en cuenta que los antónimos suelen ser intercambiables si solo nos fijamos en las palabras que los rodean – por ejemplo, “bueno” y “malo” suelen aparecer en contextos similares). Los tamaños de ventana más grandes nos llevana a <em>embeddings</em> en donde la similitud es más bien una medida del nivel de relación entre dos palabras. En la práctica, probablemente tengas que proveer <a href="https://youtu.be/ao52o9l6KGw?t=287">anotaciones</a> que guíen el proceso de generación de <em>embeddings</em> y entreguen un sentido mejor de similitud. El tamaño de ventana por default en <em>Gensim</em> es 5 (dos palabras antes y dos palabras después de la palabra de entrada).</p>

<p><img src="http://jalammar.github.io/images/word2vec/word2vec-negative-samples.png" alt="" /></p>

<p>El número de ejemplos negativos es otro factor a considerar en el proceso de entrenamiento, el <em>paper</em> original recomienda de 5 a 20 como un buen número de ejemplos negativos. También menciona que de 2 a 5 suele ser suficiente cuando se tiene un <em>dataset</em> de buen tamaño. El default en Gensim es 5 ejemplos negativos.</p>

<h2 id="conclusión">Conclusión</h2>

<blockquote>
  <p>“Si sale de tu dominio, entonces estás interactuando con inteligencia, no con automatización.” ~ Dios Emperador de Dune</p>
</blockquote>

<p>Espero que ahora ya comprendas qué son los <em>embeddings</em> y el algoritmo detrás de <em>word2vec</em>. También espero que cuando leas un artículo científico mencionando <em>“skipgram with negative sampling”</em> (como los que mencioné al principio), entiendas lo que significan estos conceptos. Como siempre, cualquier comentario es bien apreciado <a href="https://twitter.com/JayAlammar">@JayAlammar</a></p>

<h2 id="referencias-y-recursos-para-seguir-leyendo">Referencias y recursos para seguir leyendo</h2>
<ul>
  <li><a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a> [pdf]</li>
  <li><a href="https://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a> [pdf]</li>
  <li><a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A Neural Probabilistic Language Model</a> [pdf]</li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a> by Dan Jurafsky and James H. Martin is a leading resource for NLP. Word2vec is tackled in Chapter 6.</li>
  <li><a href="https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984">Neural Network Methods in Natural Language Processing</a> by <a href="https://twitter.com/yoavgo">Yoav Goldberg</a> is a great read for neural NLP topics.</li>
  <li><a href="http://mccormickml.com/">Chris McCormick</a> has written some great blog posts about Word2vec. He also just released <a href="https://www.preview.nearist.ai/paid-ebook-and-tutorial">The Inner Workings of word2vec</a>, an E-book focused on the internals of word2vec.</li>
  <li>Want to read the code? Here are two options:
    <ul>
      <li>Gensim’s <a href="https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py">python implementation</a> of word2vec</li>
      <li>Mikolov’s original <a href="https://github.com/tmikolov/word2vec/blob/master/word2vec.c">implementation in C</a> – better yet, this <a href="https://github.com/chrisjmccormick/word2vec_commented/blob/master/word2vec.c">version with detailed comments</a> from Chris McCormick.</li>
    </ul>
  </li>
  <li><a href="http://sro.sussex.ac.uk/id/eprint/61062/1/Batchkarov,%20Miroslav%20Manov.pdf">Evaluating distributional models of compositional semantics</a></li>
  <li><a href="http://ruder.io/word-embeddings-1/index.html">On word embeddings</a>, <a href="http://ruder.io/word-embeddings-softmax/">part 2</a></li>
  <li><a href="https://www.amazon.com/Dune-Frank-Herbert/dp/0441172717/">Dune</a></li>
</ul>

<p><small>Alammar, Jay (2019). The Illustrated Word2vec [Blog post]. Retrieved from <a href="http://jalammar.github.io/illustrated-word2vec/">http://jalammar.github.io/illustrated-word2vec/</a> </small></p>

<hr />

<p>Sin más les recuerdo que como siempre, quedo atento a sus dudas y comentarios en mi cuenta de Twitter <a href="https://twitter.com/io_exception">@io_exception</a>, en donde me pueden con contactar para hablar sobre ciencia de datos, ingeniería de software y muchas cosas más.</p>


                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscríbete a 🌮 tacos de datos | Aprende visualización de datos en español.</h3>
                    <p>Recibe las mejores publicaciones directamente a tu caja de entrada</p>
                    <div id="revue-embed">
  <form
    action="http://boletin.tacosdedatos.com/add_subscriber"
    method="post"
    id="revue-form"
    name="revue-form"
    target="_blank"
  >
    <div class="revue-form-group">
      <div>
        <label for="member_email">Correo electrónico</label>
        <input
          class="revue-form-field"
          placeholder="Tu correo electrónico"
          type="email"
          name="member[email]"
          id="member_email"
        />
      </div>
      <div class="revue-form-group">
        <label for="member_first_name"
          >Nombre <span class="optional">(Opcional)</span></label
        >
        <input
          class="revue-form-field"
          placeholder="Nombre (opcional)"
          type="text"
          name="member[first_name]"
          id="member_first_name"
        />
      </div>
      <div class="revue-form-group">
        <label for="member_last_name"
          >Apellidos <span class="optional">(Opcional)</span></label
        >
        <input
          class="revue-form-field"
          placeholder="Apellidos (opcional)"
          type="text"
          name="member[last_name]"
          id="member_last_name"
        />
      </div>
      <div class="revue-form-actions">
        <input
          type="submit"
          value="Subscribe"
          name="member[subscribe]"
          id="member_submit"
        />
      </div>
    </div>
    <div class="revue-form-footer">
      Al registrarte declaras aceptar los
      <a target="_blank" href="https://www.getrevue.co/terms"
        >términos y condiciones de uso</a
      >
      y la
      <a target="_blank" href="https://www.getrevue.co/privacy"
        >política de privacidad</a
      >
      de Revue.
    </div>
  </form>
</div>

                </section>
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                
                    
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/images/yo_io_exception.jpg" alt="io_exception" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/io_exception">Antonio Feregrino Bolaños</a></h4>
                                
                                    <p>Soy científico de datos pero crecí siendo desarrollador de software.</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/io_exception">Lee Más</a>
                        </div>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            this.page.url = 'https://old.tacosdedatos.com/word-to-vec-ilustrado';
                            this.page.identifier = 'Word2vec ilustrado';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://tacosdedatos.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/images/blog-cover.png)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; 🌮 tacos de datos | Aprende visualización de datos en español. &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/python/">Python</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/mejorando-barplots">Mejorando nuestros gráficos de barras</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/texto-vectores">De texto a vectores (parte 1)</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/analisis-texto">Introducción al análisis de texto</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/python/">
                                
                                    See all 15 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                
    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/tableau-mapas">
                <div class="post-card-image" style="background-image: url(/assets/blogposts/020.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/tableau-mapas">
                <header class="post-card-header">
                    
                        
                            
                               <span class="post-card-tags">Tableau</span>
                            
                        
                            
                                <span class="post-card-tags">Mapas</span>
                            
                        
                    

                    <h2 class="post-card-title">Creación de Mapas con Tableau</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/karen.jpg" alt="Karen Santoyo Tapia" />
                        
                        <span class="post-card-author">
                            <a href="/author/karen/">Karen Santoyo Tapia</a>
                        </span>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                
    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/texto-vectores">
                <div class="post-card-image" style="background-image: url(/assets/detrasdelavis/004.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/texto-vectores">
                <header class="post-card-header">
                    
                        
                            
                               <span class="post-card-tags">Python</span>
                            
                        
                            
                               <span class="post-card-tags">Skelarn</span>
                            
                        
                            
                                <span class="post-card-tags">Texto</span>
                            
                        
                    

                    <h2 class="post-card-title">De texto a vectores (parte 1)</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/yo_io_exception.jpg" alt="Antonio Feregrino Bolaños" />
                        
                        <span class="post-card-author">
                            <a href="/author/io_exception/">Antonio Feregrino Bolaños</a>
                        </span>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="https://old.tacosdedatos.com/">
            
                <img src="/assets/icons/favicon.ico" alt="🌮 tacos de datos | Aprende visualización de datos en español. icon" />
            
            <span>🌮 tacos de datos | Aprende visualización de datos en español.</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Word2vec ilustrado</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">comparte esto <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Word2vec+ilustrado&amp;url=https://old.tacosdedatos.com/word-to-vec-ilustrado"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://old.tacosdedatos.com/word-to-vec-ilustrado"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://old.tacosdedatos.com/">🌮 tacos de datos | Aprende visualización de datos en español.</a> &copy; 2021</section>
                <section class="poweredby">Publicado con <a href="https://jekyllrb.com/">Jekyll</a>, código abierto en 
                    <a href="https://github.com/tacosdedatos/website" target="_blank" rel="noopener">GitHub</a> usando
                    <a href="https://github.com/jekyller/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">lo <b>+</b> nuevo</a>
                    <a href="https://tacosdedatos.com/etiquetas" target="_blank" rel="noopener">etiquetas</a>
                    <!-- <a href="https://facebook.com/tacosdedatos" target="_blank" rel="noopener">Facebook</a> -->
                    <!-- <a href="https://twitter.com/tacosdedatos" target="_blank" rel="noopener">Twitter</a> -->
                    <a href="https://instagram.com/chekos.visuals" target="_blank" rel="noopener">instagram</a>
                    
                    <a href="https://join.slack.com/t/tacosdedatos/shared_invite/enQtNTQyOTE3NzE5NDE1LTA2MWZhMGE3NzNhYTA0Yjc1Yjk0NTZjNzM4M2VjOGIzOTA4YTc2ZjlkYjIyODRmYjA0MjVlMjExNjRjYWQ0NDQ" target="_blank" rel="noopener">slack</a>
                    <a href="https://patreon.com/tacosdedatos/" target="_blank" rel="noopener">patreon</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                    <img class="subscribe-overlay-logo" src="/assets/images/alt-blog-icon.png" alt="🌮 tacos de datos | Aprende visualización de datos en español." />
                
                <h1 class="subscribe-overlay-title">Subscríbete a 🌮 tacos de datos | Aprende visualización de datos en español.</h1>
                <p class="subscribe-overlay-description">¡Mantente al tanto! Recibe las mejores publicaciones directamente a tu caja de entrada.</p>
                <div id="revue-embed">
  <form
    action="http://boletin.tacosdedatos.com/add_subscriber"
    method="post"
    id="revue-form"
    name="revue-form"
    target="_blank"
  >
    <div class="revue-form-group">
      <div>
        <label for="member_email">Correo electrónico</label>
        <input
          class="revue-form-field"
          placeholder="Tu correo electrónico"
          type="email"
          name="member[email]"
          id="member_email"
        />
      </div>
      <div class="revue-form-group">
        <label for="member_first_name"
          >Nombre <span class="optional">(Opcional)</span></label
        >
        <input
          class="revue-form-field"
          placeholder="Nombre (opcional)"
          type="text"
          name="member[first_name]"
          id="member_first_name"
        />
      </div>
      <div class="revue-form-group">
        <label for="member_last_name"
          >Apellidos <span class="optional">(Opcional)</span></label
        >
        <input
          class="revue-form-field"
          placeholder="Apellidos (opcional)"
          type="text"
          name="member[last_name]"
          id="member_last_name"
        />
      </div>
      <div class="revue-form-actions">
        <input
          type="submit"
          value="Subscribe"
          name="member[subscribe]"
          id="member_submit"
        />
      </div>
    </div>
    <div class="revue-form-footer">
      Al registrarte declaras aceptar los
      <a target="_blank" href="https://www.getrevue.co/terms"
        >términos y condiciones de uso</a
      >
      y la
      <a target="_blank" href="https://www.getrevue.co/privacy"
        >política de privacidad</a
      >
      de Revue.
    </div>
  </form>
</div>

            </div>
        </div>
    

    <!-- highlight.js -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script> -->
    <script src="/assets/js/highlight.pack.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre code').forEach((block) => {
            hljs.highlightBlock(block);
        });
    });
    </script>
    <!-- prism.js -->
    <!-- <script type="text/javascript" src="/assets/js/prism.js"></script> -->
    

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>

    <!-- <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script> -->


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-133541532-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
